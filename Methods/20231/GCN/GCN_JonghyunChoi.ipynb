{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Convolutional Networks (GCN) Methodology"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Author information**\n",
    "\n",
    "- Name: Jong hyun Choi\n",
    "- email address: 21700741@handong.edu\n",
    "- GitHub: https://github.com/entirelifetoGod"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1. Background of methodology\n",
    "##### Part 1-1. The Importance of Graph Data\n",
    "Graphs are used to represent various forms of data in the real world. Data must be modeled in graph form in various fields such as social networks, web graphs, and molecular structures. Predictive modeling of these graph data is important, and advances in deep learning models must be applicable to graph data. The graphs mentioned here are not commonly thought bar graphs, line graphs, but rather to determine the relationship between nodes. Specifically, a graph is a set of nodes(= verticles) connected by directed edges, where nodes and edges are generally composed of expert knowledge or intuition about the problem to be solved.<br>\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "  <img src=\"graph_1.png\" alt=\"Image\" style=\"width:500px;height:250px;\">\n",
    "  <figcaption>Directed vs. Undirected Networks</figcaption>\n",
    "</div>\n",
    "\n",
    "##### Part 1-2. Start of model describing graph data – GNN\n",
    "Graph Neural Networks (GNN) are performed as a method of modeling the relationship between nodes in a graph. The basis of GNN is to model the relationship between the nodes in the graph, and to generate a representation for it. \n",
    "\n",
    "- **Summary of Methodology – GNN**\n",
    "\n",
    "In order to effectively deliver the GNN model, I will explain the operating principles of GNN through the theme of \"Predicting the influence of the corresponding user when the network relationship of SNS users is given as a graph.\" GNN is a form that receives the input which is a graph with a relationship between nodes, and makes embedding, then the weights are calculated to generate an output \n",
    "<div style=\"text-align: left;\">\n",
    "  <img src=\"graph_2.png\" alt=\"Image\" style=\"width:700px;height:350px;\">\n",
    "  <figcaption>GNN Structure</figcaption>\n",
    "</div>\n",
    "\n",
    "A representative architecture that can be used to embed graphs is Recurrent Neural Networks (RNN). RNN is a special structure that can be used for chain-connected structural data, characterized by combining the hidden of the previous time step with the input of the current time step to generate the current hidden representation.\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "  <img src=\"graph_3.png\" alt=\"Image\" style=\"width:400px;height:300px;\">\n",
    "</div>\n",
    "\n",
    "To construct a GNN using an RNN, we consider the following two things.\n",
    "- Embeds each node which is used as an RNN unit\n",
    "- Define a neural network by edge (node-to-node connection) type, there may be various edge types in the graph, and the network is configured differently depending on the type \n",
    "\n",
    "For example, if there is a \"friends\" relationship and a \"follow\" relationship on SNS, these two are expressed as networks using different weights.\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "  <img src=\"graph_4.png\" alt=\"Image\" style=\"width:500px;height:300px;\">\n",
    "</div>\n",
    "\n",
    "Suppose each node as a recurrent unit. Each node can view the nearest node as a point in time (t-1) and generate a new hidden using the current unit. For example, in the figure below, NN_1 can be used to combine information for the node 1 closest to the node 1 in the middle to generate a new representation (indicated by a blue block).\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "  <img src=\"graph_5.png\" alt=\"Image\" style=\"width:400px;height:300px;\">\n",
    "</div>\n",
    "\n",
    "In the same way, applying RNN to the four nearest nodes gives four hidden nodes. <br> If we ignore the order between nodes, we can add these four hidden (sum) to create a new representation for the middle node. The presentation generated in this way is now a presentation containing information on adjacent nodes.\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "  <img src=\"graph_7.png\" alt=\"Image\" style=\"width:350px;height:300px;\">\n",
    "</div>\n",
    "\n",
    "In this example, an RNN considering only one step adjacent, (t-1) step, is an example, but two and three step adjacent nodes can also be considered. That is, the number of time steps k to be considered in the GNN is set as the hyperparameter of the network. The embedding considering more time steps will have more node information.\n",
    "<br><br>\n",
    "\n",
    "##### Part 1-3. Why did GCN appear?\n",
    "\n",
    "* **Limits of GNN**\n",
    "\n",
    "Previously, Graph Neural Network (GNN) described above was used as a predictive model for graph data. However, existing GNNs have limited scalability and efficiency due to problems such as information loss and large computational volume when propagating information. GCN has emerged in a situation where improvement is needed.\n",
    "\n",
    "* **Complexity of Graph Structure**\n",
    "\n",
    "Graphs have complex structures of nodes and edges. Each node sends and receives information through its relationship with neighboring nodes, and the complexity of these graph structures is difficult to handle properly with traditional deep learning models, requiring a graph-specific model.\n",
    "<br><br>\n",
    "\n",
    "##### Part 1-4. Application of GCN in real-world\n",
    "GNNs are good for analyzing and predicting complex networks where it is known that each element has a specific relationship with each other. For example, researchers define the nodes and edges of the graph and use GCN, such as atoms in molecules, users of social networks, cities in transportation systems, and neurons in the brain.\n",
    "\n",
    "* Social Network Analysis: On a social network, nodes represent user relationships and edges represent user relationships. GCN can be used for tasks such as friend referrals, community detection, and online social influence analysis, taking into account the nature and relationships of nodes in these social networks.\n",
    "\n",
    "* Molecular Graph Analysis: Molecules can be represented by graphs of atoms and bonds. GCN learns patterns of atoms and bonds in molecular structures and can be utilized for molecular graph analysis such as predicting the properties of molecules, analyzing the properties of compounds, and designing new compounds.\n",
    "\n",
    "* Road Network Analysis: Road networks can graph the roads and traffic in cities. GCNs can be used in road networks for tasks such as traffic flow, congestion prediction, and road expansion planning.\n",
    "\n",
    "* Recommended System: Graph the interaction between users and items. GCN can be used to build a personalized recommendation system, taking into account the nature and interaction of users and items.\n",
    "\n",
    "* Knowledge Graph Analysis - Knowledge graphs are used as graphs to represent objects and their relationships. For example, you can graph objects, attributes, relationships, etc. in an ontology or knowledge base of knowledge. GCN can be used for tasks such as inference, classification, and question-and-answer, taking into account the characteristics and relationships of objects in knowledge graphs.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2. Key concept of methodology\n",
    "##### Part 2-1. GCN's Key Strengths\n",
    "* Utilize regional information: GCN updates attributes based on each node's interaction with neighbors. This allows you to make predictions using local information on the node. This is an advantage that reflects the regional patterns of graph data well and improves predictive performance.\n",
    "\n",
    "* Computational efficiency: GCN uses adjacency matrices to model the node's interactions with neighbors. This can be implemented as computationally efficient matrix operations, which are advantageous in predictive modeling for large-scale graph data.\n",
    "\n",
    "* Consideration of graph structure: GCN performs predictions by reflecting the structure of graph data. By using the connection relationship of the graph to model the interactions between nodes, predictions are possible considering the characteristics and interactions of the graph. This is especially useful for prediction problems in graph data.\n",
    "<br><br>\n",
    "\n",
    "##### Part 2-2. Description of methodology including mathematical equations\n",
    "* **Brief summary of CNN**\n",
    "\n",
    "One of the most representative ways in which GCN processes graph data differently is the application of convolution operations.\n",
    "\n",
    "Convolutional neural networks (CNNs), which are widely used for image data analysis, operate by dividing images into small areas and continuing to collect local information. In general, convolution and pooling operations are repeatedly performed in networks using CNN, and convolution can be considered to be a task that extracts information from each area, and pooling operations can be considered to be a task that only leaves important information (image classification, etc.) among the extracted information.\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "  <img src=\"graph_8.png\" alt=\"Image\" style=\"width:1000px;height:400px;\">\n",
    "</div>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "* **GCN Formulation**\n",
    "\n",
    "The Given data is graph format. Graph involves verticels(= nodes) and edges.<br>\n",
    "\n",
    "GCN receives the following as input. <br> Size of the input feature matrix = $N × F (0)$,   N: number of nodes, $F(0)$: input feature dimension on each node <br>\n",
    "Adjacency matrix (relationships of nodes in a graph), Expressions for graph structure: Size = $N * N$\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "  <img src=\"graph_9.png\" alt=\"Image\" style=\"width:1000px;height:400px;\">\n",
    "</div>\n",
    "\n",
    "In this case, the hidden layer of GCN may be expressed as follows.\n",
    "\n",
    "$H^i=f(H^(i-1),A), where H^0=X, f=propagation$\n",
    "\n",
    "Here, each layer $H^i$ means $N*F(i)$ feature matrix (representation of each row for a node). Features of each layer are aggregated according to the proposal rule and transferred to the next layer. Looking at this frame, the variations of the various GCNs eventually depend on how the propagation rule is determined. Just as the first layer captures basic characteristics such as edge and color in CNN, and the subsequent layer captures abstract features, GCN also draws more abstract characteristics from the graph as it goes to the later layer.\n",
    "<br><br>\n",
    "\n",
    "* **Simple Propagation Rule**\n",
    "\n",
    "$f(H^i,A)= σ(AH^i W^i )$, where $σ$ is a non-linear activation function\n",
    "\n",
    "$W^i$ is the weight matrix of the i-th layer and has an $F(i) * F(i+1)$ dimension (changing the dimension of feature). One layer of weight is similar to CNN's convolution operation in that it shares across all nodes in the graph.\n",
    "\n",
    "Since the matrix has a binding law, $A * H^i * W^i$can be calculated as $A * (H^i * W^i)$. The $H^i * W^i$ operation is to extract information by changing the feature of the $F(i)$ dimension in the i-th layer to the $F(i+1)$ dimension. The results of this operation are expressed in the sky blue matrix in the figure below.\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "  <img src=\"graph_10.png\" alt=\"Image\" style=\"width:900px;height:400px;\">\n",
    "</div>\n",
    "\n",
    "Now, multiplying the newly created matrix by the adjacency matrix, the resulting value of $(i, j)$ in the matrix is obtained as the sum of the $j-th$ matrix values of all nodes connected to node $i$. That is, the feature is updated by collecting information on nodes connected to each node.\n",
    "\n",
    "However, there are two problems when calculating in this way.<br>\n",
    "First, Your own feature is not reflected when collecting characteristics.For example, since the first node does not point to any node, no information is reflected. In other words, only nodes with self-loops pointing to themselves can reflect their information when collecting features.\n",
    "Second, a node with a lot of connections has a large value in feature presentation, and a node with a few connections has a smaller value. As a result, the gradient for node 3 connected to many nodes explodes. In the case of nodes 1 and 2 with fewer connections, gradients may be lost (vanishing gradient)\n",
    "Therefore, here is two solution.\n",
    "First, include Self-loop. Give each node a self loop, so that the diagonal element of the adjacency matrix A has a value of 1. In this way, you can always consider your characteristics when collecting features.\n",
    "Second, regularize feature presentation. Back-propagation can be stabilized by normalizing the calculated feature for the node's connectivity. The connectivity of nodes is called a dimension, and normalization can be achieved by multiplying the inverse of the dimension (D) of adjacent matrix A.<br>\n",
    "\n",
    "$f(H^i,A)=σ(D^-1 AH^i W^i)$ <br>\n",
    "\n",
    "- **Detailed approaches of GCN**\n",
    "\n",
    "1. Detailed formula considering dimensions\n",
    "\n",
    "Below is a detailed formula considering the dimensions of each matrix, which summarizes the situation occurring in the first layer as an equation.\n",
    "\n",
    "Hnext[N*F] = σ(A[N*N] * X[N*D] * W[D*F])$\n",
    "\n",
    "In the above equation, the calculation of $X[N*D] * [D*N]$ is a general linear embedding. Then, the data of each node can be embossed from the D-dimensional to the F-dimensional feature dimension, and as soon as A is multiplied, each node performs filtering by summing the features of the nodes primarily connected to it. It then passes through non-linear activation to make the final calculation. If this layer continues to be stacked, it will be possible to get the feature of the Nth connected node (also known as N hop) beyond the information of the first connected node. In other words, GCN also extracts information about the entire graph, just as the layers increase from local feature to global feature.\n",
    "<br>\n",
    "\n",
    "2. Deformation of adjacent matrix\n",
    "\n",
    "If the weight of the relationship between nodes is already known, the GCN may be configured by reflecting this. Typically, to do this, we use the method of realistically representing and weighting the values of adjacent matrices.<br>\n",
    "\n",
    "To convert an existing binary adjacency matrix to a weighted adjacency matrix:\n",
    "\n",
    "* Generate Weight Matrix to generate a matrix representing the weight of the relationship between nodes. This matrix has the same size as the adjacent matrix, and each element has a weight value for that relationship.\n",
    "* Performs scaling to normalize the generated weight matrix. Typically, scaling is performed by dividing each row or column of the weight matrix by the sum. This allows you to adjust the weight to the range [0, 1], or to have a unit sum.\n",
    "* Replace adjacency matrix. Replace an existing binary adjacency matrix with a weighted adjacency matrix. This new adjacency matrix has real numbers and accurately reflects the relationship weights between nodes.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3. Example\n",
    "- **Objective**: Use GCN to predict the categories of papers on the Cora dataset.\n",
    "- **Dataset information**: Cora is one of the widely used graph datasets in the field of machine learning, containing information on computer science papers. This dataset contains the title, author, abstract, label, and citation information of the paper.\n",
    "- **Code Progress**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1. Load PyTorch package to use GCN and load the data set provided by pytorch to load the Cora data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid, CoraFull, Actor\n",
    "\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding example loads the Cora dataset in graph format. Each paper is represented by a node in the graph, and the citation relationship between the nodes is represented by an edge. The characteristic value of the paper is the conversion of text data into a Bag-of-Words vector."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step2. Load the Cora dataset. \n",
    "Cora data contains information on 2708 papers, and there are 1,0556 edges representing the relationship between each paper. And there are 1433 features in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DATASET || nodes | edges | features \n",
      "---------------------------------------\n",
      " Cora     ||   2708|  10556|     1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Load the Cora dataset\n",
    "cora_dataset =  Planetoid(root='/tmp/Cora', name='Cora')\n",
    "cora_data = cora_dataset[0]\n",
    "\n",
    "# print dataset info\n",
    "print(\"  DATASET || nodes | edges | features \")\n",
    "print(\"---------------------------------------\")\n",
    "# Q1-a: Print the number of nodes, edges, and features of the Cora network\n",
    "print(\" {0:9}||{1:7}|{2:7}|{3:9}\".format(\"Cora\",cora_data.num_nodes, cora_data.num_edges, cora_data.num_node_features))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step3. Define the GCN model. \n",
    "The GCN model is used to predict the categories of each paper using graph structure and characteristic values. When I made the model, I made 2 GCN layers and set the output of the last layer to 7. The reason why I set it to 7 is that there are seven types of papers. The GCN class was then assigned to a variable called model, and the Cora dataset was put in.\n",
    "\n",
    "The seven categories of papers are as follows. <br>\"Neural_Networks\", \"Probabilistic_Methods\", \"Genetic_Algorithms\", \"Theory\", \"Case_Based\", \"Reinforcement_Learning\", \"Rule_Learning\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(cora_dataset.num_node_features, 128)\n",
    "        self.conv2 = GCNConv(128, 7)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0334, -1.8615, -1.9809,  ..., -1.7852, -1.9633, -2.0140],\n",
       "        [-2.0146, -1.9759, -2.0034,  ..., -1.7794, -1.8719, -2.0250],\n",
       "        [-1.9576, -2.0023, -2.1410,  ..., -1.8247, -1.8854, -2.0338],\n",
       "        ...,\n",
       "        [-1.9223, -2.0874, -1.9010,  ..., -1.8916, -1.8708, -2.2816],\n",
       "        [-2.0097, -1.9579, -1.9893,  ..., -1.7574, -1.8830, -2.0049],\n",
       "        [-2.0116, -1.9433, -1.9807,  ..., -1.8163, -1.9034, -2.0170]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCN()\n",
    "model(cora_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4. Learn the model. \n",
    "It is a process of comparing actual category information with prediction results. In other words, the model calculates the difference between the predicted and actual categories to obtain losses, which improves the model by updating the weights. The learning process updated weights through backpropagation algorithms, used Adam optimizer, and adjusted the hyperparameters by setting the learning rate to 0.01 and weight_decay to 5e-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = cora_dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5. Check the performance of the model.\n",
    "The model's performance accuracy was measured, and the result showed an accuracy of 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8050\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, GCN was used to predict the categories of papers on the Cora dataset, and the model was trained using the difference between the actual category and the prediction result, and a model with predictive performance of about 80% accuracy was successful.\n",
    "\n",
    "The GCN model was used to implement better performance than when only existing features were used, considering the relationship between papers. We emphasize that the GCN model is a model that can predict existing problems with better performance when we know the relationship between each sample as above. Therefore, it suggests that it is a model that can emit light in the context of biological molecular relations and variable traffic networks, which have previously been difficult to predict in detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d288b0b05eff9a885f46bca58a1e22eaa20d9eeebab83492fa79239d8adcb3ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
