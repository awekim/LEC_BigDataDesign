{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5dbcf6c7",
   "metadata": {},
   "source": [
    "# Random Forest Methodology"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76204dd6",
   "metadata": {},
   "source": [
    "##### Author information\n",
    "- Name: Rubiga Kim\n",
    "- email address: \n",
    "- GitHub: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1714a2f8",
   "metadata": {},
   "source": [
    "#### Part 1. Brief Background of Methodology \n",
    "\n",
    "Decision trees were widely utilized for machine learning problems before the Random Forest approach was introduced. Decision trees are straightforward, intuitive models that divide the feature space recursively according to a set of conditions. However, there are several drawbacks to decision trees that led to the creation of Random Forest. Overfitting is a major issue with decision trees. Decision trees overfit when they grow overly complicated and stick too closely to the training data, which leads to poor generalization to new data. They frequently have a large variation and are sensitive to noise or outliers. As a result, they aren't as capable to see the underlying patterns in the data and are more likely to mistake when dealing with novel, untested samples.\n",
    "\n",
    "The instability of decision trees is another drawback. They are sensitive to data changes since a slight change in the training data might result in a drastically different decision tree structure. When generating forecasts or evaluating the significance of various characteristics, this instability may be a difficulty. Due to their tendency to build excessively complicated trees or to concentrate on some attributes more than others, decision trees frequently exhibit bias. This bias may result in inaccurate predictions or analyses of the data. Given these restrictions, a method that could deal with the bias, instability, and overfitting problems that decision trees had became necessary. As a result, Random Forest was created.\n",
    "\n",
    "With the help of the ensemble learning technique Random Forest, predictions from many decision trees may be combined to produce predictions that are more reliable and accurate. Both the selection of training samples (bootstrapping) and the choice of characteristics used for each decision tree are subjected to randomization. Random Forest reduces overfitting and stabilizes the predictions by training numerous decision trees on various subsets of the data and characteristics.\n",
    "By taking into account a wider range of attributes while creating decision trees in Random Forest, the bias problem with decision trees is also addressed. The randomization added to the feature selection process aids in preventing the dominance of particular characteristics and promotes a thorough investigation of the feature space.\n",
    "\n",
    "##### Applications \n",
    "There are many applications and sectors where Random Forest may be employed. The following are two main domains where Random Forest is applicable: classification problems and regression problems. Problems with classification: Random Forest is frequently used to solve classification problems. Both binary and multiple-class classification issues are supported. Examples include the identification of spam emails, sentiment analysis, the diagnosis of illnesses, the prediction of customer turnover, and picture categorization. Random Forest may also be used to address problems with regression in which the objective is to forecast a continuous target variable. Complex interactions between features and targets can be handled by it. Examples include stock market research, demand forecasting, and property price prediction.\n",
    "\n",
    "##### Methodology\n",
    "<img src ='https://www.tibco.com/sites/tibco/files/media_entity/2021-05/random-forest-diagram.svg'>\n",
    "Flowchart-like structure known as a decision tree, where each internal node stands in for a feature or attribute, each branch for a decision rule, and each leaf node for the result or class label. Using the feature values, a decision tree divides the input space into regions. It asks, “What attribute will enable me to divide the current observations into groups that are as distinct from one another as feasible (and whose members are as similar to one another as possible)?”\n",
    "\n",
    "Then, bagging, also known as bootstrap integration, allows individual decision trees to generate very different results by randomly sampling from a dataset and replacing data, meaning that each tree uses only a subset of the data instead of including all of the available data. These individual trees then make decisions based on the data they have and predict outcomes based only on these data points.This means that each random forest has trees that are trained on different data and use different features to make decisions. After, the class with the most votes become the prediction made by our model from each individual tree in the random forest. \n",
    "\n",
    "Depending on whether you are using classification problems or regression problems, the Index or the formula used to determine how nodes on a decision tree branch are ordered. When solving regression problems, the MSE(mean squared error) is utilized. \n",
    "\n",
    "$$\n",
    "  MSE = \\frac{1}{N} \\sum \\limits _{i=1} ^{N} (fi-yi)^2\n",
    "$$\n",
    "\n",
    "For the N number of datapoints, fi is the predicted value returned by the model and yi is the actual value for datapoint i. This formula evaluates the distance between each node and the expected actual value. \n",
    "\n",
    "However, when using random forests on classification data, the Gini index or the entropy formula is utilized. \n",
    "\n",
    "$$ Gini = 1- \\sum \\limits _{i=1} ^{C} (p_{i} )^2 $$\n",
    " \n",
    "The formula above calculates the Gini of each branch on a node based on the class and probability, indicating which branch is more likely to occur. Pi stands for the class’s relative frequency in the dataset and c stand for the total number of cases. \n",
    "\n",
    "$$ Entropy = \\sum \\limits _{i=1} ^{C} - p_{i} * log_{2}(p_{i}) $$ \n",
    "\n",
    "Entropy examines the likelihood of a particular result to determine which branch the node should take. It is more mathematically complex than the Gini index since a logarithmic function is utilized to calculate it.\n",
    "\n",
    "\n",
    "##### Strength\n",
    "The strength of this algorithm is as follows. There is a low correlation between models. Uncorrelated models have the ability to provide ensemble forecasts that are more accurate than any of the individual predictions. As long as they don't consistently all mistake in the same direction, the trees shield each other from their individual faults, which accounts for this result. Many trees will be right while some may be wrong, allowing the group of trees to travel in the proper direction. The following conditions must be met for random forest to function effectively. This allows the methodologies to be robust to outliers and noisy datapoints, and overfitting, as they are unlikely to consistently affect the construction of multiple decision trees, and the randomness in the selection of features helps create diversity in the forest. This also has an advantage of improving the accuracy of the model. \n",
    "\n",
    "Also, decision trees are sensitive to the data they are trained on, and even little adjustments to the training set can produce dramatically different tree architectures.This problem may be solve with the bagging procedure, where each individual tree produces its output from the different set of datasets.\n",
    "\n",
    "Finally, random forests offer a measure of feature relevance, enabling researchers to pinpoint the features that will have the most impact on the prediction job. This data can help with feature selection, locating relevant variables, and getting a better understanding of the underlying patterns in the data.They are also capable of capturing complex nonlinear relationships. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57e6eca2",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918f9bb",
   "metadata": {},
   "source": [
    "This example aims to train a random forest classfier model on the  Titanic dataset to predict whether the passengers on the ship survived or not on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f2be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4266070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b990ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Age\"].fillna(train[\"Age\"].median(skipna=True), inplace=True)\n",
    "test[\"Age\"].fillna(test[\"Age\"].median(skipna=True), inplace=True)\n",
    "train[\"Embarked\"].fillna(train['Embarked'].value_counts().idxmax(), inplace=True)\n",
    "test[\"Embarked\"].fillna(test['Embarked'].value_counts().idxmax(), inplace=True)\n",
    "train.drop('Cabin', axis=1, inplace=True)\n",
    "test.drop('Cabin', axis=1, inplace=True)\n",
    "test['Fare'].fillna(test['Fare'].dropna().median(), inplace=True)\n",
    "train.drop('SibSp', axis=1, inplace=True)\n",
    "train.drop('Parch', axis=1, inplace=True)\n",
    "test.drop('SibSp', axis=1, inplace=True)\n",
    "test.drop('Parch', axis=1, inplace=True)\n",
    "train = pd.get_dummies(train, columns=[\"Pclass\",\"Embarked\",\"Sex\"], drop_first=True)\n",
    "test = pd.get_dummies(test, columns=[\"Pclass\",\"Embarked\",\"Sex\"], drop_first=True)\n",
    "train.drop('PassengerId', axis=1, inplace=True)\n",
    "test.drop('PassengerId', axis=1, inplace=True)\n",
    "train.drop('Name', axis=1, inplace=True)\n",
    "train.drop('Ticket', axis=1, inplace=True)\n",
    "test.drop('Name', axis=1, inplace=True)\n",
    "test.drop('Ticket', axis=1, inplace=True)\n",
    "train.drop('Embarked_Q', axis=1, inplace=True)\n",
    "test.drop('Embarked_Q', axis=1, inplace=True)\n",
    "train.drop('Embarked_S', axis=1, inplace=True)\n",
    "test.drop('Embarked_S', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb67de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Age         0\n",
       "Fare        0\n",
       "Pclass_2    0\n",
       "Pclass_3    0\n",
       "Sex_male    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71419e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         0\n",
       "Fare        0\n",
       "Pclass_2    0\n",
       "Pclass_3    0\n",
       "Sex_male    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1a7977d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Fare', 'Pclass_2', 'Pclass_3', 'Sex_male'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>39.0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>38.5</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>27.0</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age      Fare  Pclass_2  Pclass_3  Sex_male\n",
       "0    34.5    7.8292         0         1         1\n",
       "1    47.0    7.0000         0         1         0\n",
       "2    62.0    9.6875         1         0         1\n",
       "3    27.0    8.6625         0         1         1\n",
       "4    22.0   12.2875         0         1         0\n",
       "..    ...       ...       ...       ...       ...\n",
       "413  27.0    8.0500         0         1         1\n",
       "414  39.0  108.9000         0         0         0\n",
       "415  38.5    7.2500         0         1         1\n",
       "416  27.0    8.0500         0         1         1\n",
       "417  27.0   22.3583         0         1         1\n",
       "\n",
       "[418 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train.copy()\n",
    "train_data.drop('Survived', axis=1, inplace=True)\n",
    "\n",
    "train_data.describe()\n",
    "cols = train_data.columns\n",
    "print(cols)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03eaf53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() #transform data to 0 or 1 \n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data = scaler.fit_transform(test)# 0--> did not survive, 1 --> survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94820f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_data, columns=[cols])\n",
    "test_data = pd.DataFrame(test_data, columns=[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "454a028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#build a random foreset classifier model\n",
    "y = train[\"Survived\"] # predict the survived variable\n",
    "X = train_data #uses every variable except the surived variable\n",
    "X_test = test_data #assigns preprocessed test data to test variable\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=7)\n",
    "#create a randomforestclassifier with 200 decision tress, max_depth of 10, and random seed of 7. \n",
    "model.fit(X, y) #trains the random forest model using the training data (X as feature and y as label)\n",
    "predictions = model.predict(X_test)#predicts the survival outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "671dbc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0900a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "003dda87",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "166bd04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d288b0b05eff9a885f46bca58a1e22eaa20d9eeebab83492fa79239d8adcb3ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
