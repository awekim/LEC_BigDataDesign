{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"opqoFzleLnRA"},"source":["# Artificial Neural Network (ANN) Methodology"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"noGu1eBiLnRF"},"source":["##### Author information\n","- Name: Silvia Garces Rigol\n","- email address: silvia.grcs0200@gmail.com\n","- GitHub: https://github.com/SilviaGarces"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"M64oumDgLnRG"},"source":["#### Part 1. Brief background of ANN\n","Before the introduction of Artificial neural networks, most scientists were using different techniques. Some of them are: \n","1. Rule-based Systems. These systems relied on a set of predefined rules and logic to make decisions or perform tasks. Experts in a particular domain would manually design these rules based on their knowledge and understanding of the problem. However, they had limitations, as they were often unable to handle complex or ambiguous situations where rules may conflict or be incomplete. [1]\n","\n","2. Expert Systems. A type of AI system designed to mimic human expertise in specific domains. They incorporated knowledge from human experts into a knowledge base and used inference engines to reason and make decisions based on that knowledge. These systems typically used symbolic representations and rules, but they lacked the ability to learn and adapt from data. [2]\n","\n","3. Statistical Methods:These methods involved analyzing and modeling data using mathematical techniques such as regression, clustering, and classification. Statistical models were built based on assumptions about the underlying data distribution, and parameters were estimated from the available data. However, these models often struggled with complex patterns and non-linear relationships. [3]\n","\n","4. Feature Engineering: Prior to ANNs, feature engineering played a crucial role in machine learning. It involved manually selecting and engineering relevant features from the input data that could be used by learning algorithms to make predictions or decisions. Feature engineering required domain expertise and often consumed a significant amount of time and effort. [4]\n","\n","5. Limited Computational Power: Before the widespread availability of powerful computing resources, training complex models and processing large amounts of data were challenging tasks. This limitation made it difficult to build and train models that could handle complex problems effectively.\n","\n","The artificial neural network (ANN) was introduced in 1943 as a computational model inspired by the structure and function of the human brain. \n","Neurons have diffferent parts, first of all a signal is received from the dendrites, then the nucleus makes a summation of all the incoming signals, after that, the axon reacts if the sum is enought to activate it and finally the outcoming signal is the input for other neurons. \n","They are used to learn from and make predictions or classifications based on input data. ANNs can approximate complex functions and find patterns in data that may not be immediately obvious or easily quantifiable by humans.\n","\n","ANNS can be used in various applications including image classification, natural language processing, speech recognition, and predictive analytics. They have been successfully used in many fields, such as marketing, healthcare, finance, and robotics. ANNs can help improve decision-making processes by providing insights and predictions based on data. Overall, ANNs are a powerful tool for analyzing complex data and making predictions that can be valuable in a wide range of industries. [5]\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nCGG_MY_LnRH"},"source":["#### Part 2. Key concept of ANN\n","As explained before, ANNs are a computational model inspired by the structure and function of the human brain. They consist of interconnected nodes, called *neurons*, arranged in layers. The *input layer* receives the input data, and subsequent layers process this data through a series of nonlinear transformations before outputting a result.\n","\n","The main strength of ANNs lies in their ability to learn and generalize from data, which makes them particularly well-suited for tasks such as image classification, speech recognition, and natural language processing.\n","\n","The mathematical equation that explains the behavior of a single neuron in an ANN is the weighted sum of inputs, followed by a nonlinear activation function:\n","\n","```\n","y = f(w1 * x1 + w2 * x2 + ... + wn * xn)\n","```\n","where **y** is the output of the neuron, **x1** to **xn** are the inputs, **w1** to **wn** are the weights assigned to each input, and **f** is the activation function.\n","\n","The weights w1 to wn are adjusted during the learning process using a variant of stochastic gradient descent (SGD) called backpropagation. **Backpropagation** was intoduced in 1986 and it computes the gradient of the cost function with respect to the weights, and uses this gradient to update the weights to reduce the error between the predicted and actual outputs.\n","\n","Overall, the ability of ANNs to learn and generalize from data, combined with their ability to approximate complex functions and find patterns that may not be obvious to humans, make them a powerful tool for a wide range of applications."]},{"cell_type":"markdown","metadata":{"id":"hVZ_vL0XLnRH"},"source":["#### Part 3. Example\n","I used the PIMA indians Diabetes dataset, which can be downloaded in kaggle: https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database\n","\n","This dataset is really simple so we can try to build the model to predict some outputs."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"7eaysDRjlT9N"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"BXIfImdFmWsX"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pregnancies</th>\n","      <th>Glucose</th>\n","      <th>BloodPressure</th>\n","      <th>SkinThickness</th>\n","      <th>Insulin</th>\n","      <th>BMI</th>\n","      <th>DiabetesPedigreeFunction</th>\n","      <th>Age</th>\n","      <th>Outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>72</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>66</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>183</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>94</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>137</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>168</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n","0            6      148             72             35        0  33.6   \n","1            1       85             66             29        0  26.6   \n","2            8      183             64              0        0  23.3   \n","3            1       89             66             23       94  28.1   \n","4            0      137             40             35      168  43.1   \n","\n","   DiabetesPedigreeFunction  Age  Outcome  \n","0                     0.627   50        1  \n","1                     0.351   31        0  \n","2                     0.672   32        1  \n","3                     0.167   21        0  \n","4                     2.288   33        1  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["diabetes=pd.read_csv('diabetes.csv')\n","diabetes.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"BeL5lWKqnx99"},"outputs":[],"source":["data=diabetes.dropna()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"s0UOO1BEtTYk"},"outputs":[],"source":["data_x=data.drop(columns=['Outcome'])\n","data_y=data.Outcome"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"5u6qVa8Ep7CH"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.metrics import accuracy_score\n","from keras import metrics\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"USRH30KEqSyq"},"outputs":[],"source":["#1: Separate into training and test data\n","train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2, random_state=42)\n","#Normalize the data\n","min_max_scaler = MinMaxScaler()\n","train_norm = min_max_scaler.fit_transform(train_x)\n","test_norm = min_max_scaler.transform(test_x)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Tp7-ACq4r2_X"},"outputs":[],"source":["#2:Create ANN\n","model = Sequential()\n","model.add(Dense(312, input_dim=8, activation='relu'))# Input layer with 8 input features\n","model.add(Dense(256, activation='relu')) # hidden layer\n","model.add(Dense(128, activation='relu')) # hidden layer\n","model.add(Dense(64, activation='relu')) # hidden layer \n","model.add(Dense(1, activation='sigmoid')) # output layer"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"DJ0YXFtjs1Mq"},"outputs":[],"source":["#3: Compile model\n","model.compile(tf.keras.optimizers.Adam(learning_rate=0.001),loss='binary_crossentropy', metrics=['AUC']) \n","# We choose binary_cross entropy because our outcome is 0 or 1\n","# Adam is one of the best optimizers\n","# For metrics we want to check accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tqRZ9FhdtA8I"},"outputs":[],"source":["#4: Fit the model \n","history = model.fit(train_norm, train_y, batch_size=32, epochs=200)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gsby21DxTHUM","outputId":"43fe874f-e0a8-422a-95f2-7ad5a0bb3674"},"outputs":[{"name":"stdout","output_type":"stream","text":["20/20 [==============================] - 0s 5ms/step - loss: 0.0087 - auc: 1.0000\n","Training accuracy: 1.0\n"]}],"source":["train_loss, train_acc = model.evaluate(train_norm, train_y)\n","print('Training accuracy:', train_acc)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iLUMbu-yKI6b","outputId":"20e55232-2b47-4872-e95a-c00c41a6e048"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy: 0.6818181818181818\n"]}],"source":["#5: Make predictions of test data\n","test_pred = model.predict(test_norm)\n","pred = np.where(test_pred > 0.5, 1, 0).flatten()\n","test_acc = accuracy_score(test_y, pred)\n","print('Test accuracy:', test_acc)"]},{"cell_type":"markdown","metadata":{"id":"5doDB-RuR4rb"},"source":["#### The model\n","This is the code for creating an ANN with three different hidden layers. After creating our ANN we set the loss function and optimizer we want, there are several and depending on our data we may use on or other.\n","\n","After that we check the loss and AUC of our model, we can also check the accuracy by changing the metrics. Once the training is done, we check the accuracy of the model and start to make predictions on the test data.\n","ANNs are used for **classification**, so in this case we need to classify whether the output is 0 or 1, meaning that is has diabetes or not.\n","\n","Once we check the accuracy of the model to predict the output values for the test data, we can check if the accuracy is appropriate or not. After building the model we can tune some of the **hyperparameters** (*batch and epoch*), the **layers** and the different **loss** and **optimizer** functions."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"KKk66nqNGXJ0"},"source":["#### Part 4. References\n","[1] https://en.wikipedia.org/wiki/Rule-based_system \n","\n","[2] https://www.techtarget.com/searchenterpriseai/definition/expert-system\n","\n","[3] M. Grebovic, L. Filipovic, I. Katnic, M. Vukotic and T. Popovic, \"Overcoming Limitations of Statistical Methods with Artificial Neural Networks,\" 2022 International Arab Conference on Information Technology (ACIT), Abu Dhabi, United Arab Emirates, 2022, pp. 1-6, doi: 10.1109/ACIT57182.2022.9994218.\n","\n","[4] https://towardsdatascience.com/what-is-feature-engineering-importance-tools-and-techniques-for-machine-learning-2080b0269f10\n","\n","[5] https://www.ibm.com/topics/neural-networks\n","\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"gpuenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"d288b0b05eff9a885f46bca58a1e22eaa20d9eeebab83492fa79239d8adcb3ac"}}},"nbformat":4,"nbformat_minor":0}
